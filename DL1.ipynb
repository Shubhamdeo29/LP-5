{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSYP7uqVVrTd",
    "outputId": "a829e4ba-38c9-4c13-de47-e0f8282d8c18"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.25.2)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.4.0)\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "HvGM_IOMY8Dm"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "# from sklearn.linear_model import LinearRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "h7ulGC1kZqgD",
    "outputId": "98358e83-b103-429d-b41b-2f0f78bf1e55"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "0    0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93     0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273   \n",
       "\n",
       "     ptratio       b  lstat  medv  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90   5.33  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99   9.67  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df= pd.read_csv('BostonHousing.csv')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "Upy_l1MohdjJ"
   },
   "outputs": [],
   "source": [
    "x= df.drop('medv', axis=1)\n",
    "y = df['medv'].values  # Target variable\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "id": "4a27UyRJ9qKl",
    "outputId": "c56ab402-1245-45c9-8f03-c7fbe606fabe"
   },
   "outputs": [],
   "source": [
    "# linear_reg = LinearRegression()\n",
    "\n",
    "# linear_reg.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "p1hjXQqu9_Ms"
   },
   "outputs": [],
   "source": [
    "# y_pred = linear_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "R--XmjiAif73"
   },
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "ZBB6HjIEjAfl"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                896       \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3009 (11.75 KB)\n",
      "Trainable params: 3009 (11.75 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFci9OnfjEAD",
    "outputId": "8e155c2e-d69e-41fe-fb42-ce4080845b3e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 1s 23ms/step - loss: 590.6193 - val_loss: 567.0120\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 560.9703 - val_loss: 536.3870\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 527.2322 - val_loss: 497.8726\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 483.6113 - val_loss: 445.0110\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 423.4159 - val_loss: 374.8426\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 344.6538 - val_loss: 290.8671\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 257.2472 - val_loss: 205.8284\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 177.2528 - val_loss: 135.9736\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 119.9197 - val_loss: 92.1436\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 87.7397 - val_loss: 68.1181\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 67.0828 - val_loss: 55.0035\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 53.3876 - val_loss: 45.8792\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 42.5385 - val_loss: 40.4137\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 35.4225 - val_loss: 37.6160\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 30.8622 - val_loss: 36.4438\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 27.8280 - val_loss: 36.0008\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 25.9825 - val_loss: 35.8106\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 24.7436 - val_loss: 35.6916\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 23.4330 - val_loss: 35.2656\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 22.4730 - val_loss: 35.0408\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 21.6646 - val_loss: 34.1314\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 20.7650 - val_loss: 33.6188\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 20.0632 - val_loss: 32.9598\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 19.3806 - val_loss: 32.2992\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 18.7398 - val_loss: 31.4696\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 18.1762 - val_loss: 31.4343\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 17.6519 - val_loss: 30.9656\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 17.1851 - val_loss: 30.1495\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 16.7220 - val_loss: 29.4599\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 16.2981 - val_loss: 29.2656\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15.9058 - val_loss: 28.4276\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 15.5241 - val_loss: 27.9548\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 15.1437 - val_loss: 28.0085\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 14.8241 - val_loss: 27.5988\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.5116 - val_loss: 26.9199\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.2826 - val_loss: 26.5586\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 14.0292 - val_loss: 26.0740\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.6939 - val_loss: 26.1983\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 13.5046 - val_loss: 26.3984\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 13.2675 - val_loss: 25.7421\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 13.0161 - val_loss: 25.2684\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 12.8070 - val_loss: 24.8624\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.5798 - val_loss: 25.4096\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.5038 - val_loss: 25.9124\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 12.3398 - val_loss: 25.2709\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 12.0654 - val_loss: 24.5515\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.8950 - val_loss: 24.0343\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 11.7882 - val_loss: 24.6328\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.5979 - val_loss: 24.1625\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.4265 - val_loss: 23.4997\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 11.3101 - val_loss: 23.4091\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 11.2112 - val_loss: 23.7868\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 11.1327 - val_loss: 23.0088\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.9058 - val_loss: 23.3579\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.8197 - val_loss: 22.8271\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.6657 - val_loss: 23.1244\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.5628 - val_loss: 22.6938\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.4950 - val_loss: 22.3764\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.4023 - val_loss: 22.6099\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.3044 - val_loss: 22.6094\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 10.1515 - val_loss: 22.0292\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.1195 - val_loss: 21.8978\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 10.0518 - val_loss: 21.8259\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.9288 - val_loss: 21.8302\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.7586 - val_loss: 20.9513\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.8425 - val_loss: 20.6045\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.6459 - val_loss: 21.1078\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.6093 - val_loss: 21.3827\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 9.5120 - val_loss: 21.3096\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.4392 - val_loss: 21.7977\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.3314 - val_loss: 21.0183\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.4075 - val_loss: 20.4260\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.2970 - val_loss: 22.4807\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.2334 - val_loss: 21.6963\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.1585 - val_loss: 21.9908\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 9.0165 - val_loss: 20.9353\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.9925 - val_loss: 20.9219\n",
      "Epoch 78/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.8429 - val_loss: 20.6047\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.7024 - val_loss: 20.3348\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 8.7115 - val_loss: 19.9403\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.6213 - val_loss: 20.2782\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.5500 - val_loss: 19.8934\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.4983 - val_loss: 19.8281\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 8.4634 - val_loss: 20.1226\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.4340 - val_loss: 20.2473\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.3053 - val_loss: 20.2871\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.3514 - val_loss: 20.2560\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 8.2574 - val_loss: 19.9545\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 8.1147 - val_loss: 20.2225\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.0917 - val_loss: 19.7469\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 8.0088 - val_loss: 19.6748\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 7.9804 - val_loss: 19.5627\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.8789 - val_loss: 19.4054\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.8900 - val_loss: 19.5415\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7391 - val_loss: 18.9506\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 7.7185 - val_loss: 18.6095\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.6358 - val_loss: 18.7348\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.5719 - val_loss: 19.1487\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.6608 - val_loss: 19.0819\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 7.4916 - val_loss: 18.5270\n"
     ]
    }
   ],
   "source": [
    "history= model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94H7lW2ZjHnn",
    "outputId": "243fbf30-ef65-4e93-c14f-11717f817a22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 12.2354\n",
      "Test Loss: 12.235411643981934\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(X_test, y_test)\n",
    "print(\"Test Loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qn8fylM-jPrJ",
    "outputId": "e47f5e8a-6da5-4e59-fe35-4fba486e2a12"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n",
      "0.8331545228641508\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jl49AJbEpwlV",
    "outputId": "4210fdd4-5b29-490f-ef07-bd6f36d50391"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.235410041560982\n",
      "3.497915099249978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "mse= mean_squared_error(y_test, y_pred)\n",
    "rmse = (np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(mse)\n",
    "print(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "x_VWf1dqp0lf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "y1= model.predict(X_test).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23.6, 32.4, 13.6, 22.8, 16.1, 20. , 17.8, 14. , 19.6, 16.8, 21.5,\n",
       "       18.9,  7. , 21.2, 18.5, 29.8, 18.8, 10.2, 50. , 14.1, 25.2, 29.1,\n",
       "       12.7, 22.4, 14.2, 13.8, 20.3, 14.9, 21.7, 18.3, 23.1, 23.8, 15. ,\n",
       "       20.8, 19.1, 19.4, 34.7, 19.5, 24.4, 23.4, 19.7, 28.2, 50. , 17.4,\n",
       "       22.6, 15.1, 13.1, 24.2, 19.9, 24. , 18.9, 35.4, 15.2, 26.5, 43.5,\n",
       "       21.2, 18.4, 28.5, 23.9, 18.5, 25. , 35.4, 31.5, 20.2, 24.1, 20. ,\n",
       "       13.1, 24.8, 30.8, 12.7, 20. , 23.7, 10.8, 20.6, 20.8,  5. , 20.1,\n",
       "       48.5, 10.9,  7. , 20.9, 17.2, 20.9,  9.7, 19.4, 29. , 16.4, 25. ,\n",
       "       25. , 17.1, 23.2, 10.4, 19.6, 17.2, 27.5, 23. , 50. , 17.9,  9.6,\n",
       "       17.2, 22.5, 21.4])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = []\n",
    "for i in y1:\n",
    "    ps.append(i.item())  # Convert each NumPy float to a Python float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame({'actual':y_test,'predicted':y1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>27.621080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>34.412643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>17.515696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>25.616247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.537186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>17.9</td>\n",
       "      <td>9.448503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>9.6</td>\n",
       "      <td>11.659338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>17.2</td>\n",
       "      <td>13.636987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>22.5</td>\n",
       "      <td>23.945267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>21.4</td>\n",
       "      <td>21.899078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>102 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     actual  predicted\n",
       "0      23.6  27.621080\n",
       "1      32.4  34.412643\n",
       "2      13.6  17.515696\n",
       "3      22.8  25.616247\n",
       "4      16.1  16.537186\n",
       "..      ...        ...\n",
       "97     17.9   9.448503\n",
       "98      9.6  11.659338\n",
       "99     17.2  13.636987\n",
       "100    22.5  23.945267\n",
       "101    21.4  21.899078\n",
       "\n",
       "[102 rows x 2 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
